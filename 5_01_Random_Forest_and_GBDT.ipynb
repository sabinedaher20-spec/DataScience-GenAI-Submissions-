{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sabinedaher20-spec/DataScience-GenAI-Submissions-/blob/main/5_01_Random_Forest_and_GBDT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1xqQczl0FG-qtNA2_WQYuWePW9oU8irqJ)"
      ],
      "metadata": {
        "id": "W31V34oqo86M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.01 Random Forest and Gradient Boosting Decision Trees\n",
        "In this notebook we will extend the solution to last week's notebook by also looking at Random Forest and two GBDT implementations (the native scikit-learn implementation and also _eXtreme Gradient Boosting Decision Trees_ - _XGBDT_). The latter is basically a slighly more sophisticated implementation.\n",
        "\n",
        "We start with a prepared dataset available on my.wbs:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MHkB_ijsXnZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "8Neoy7c6aL4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('credit_data_final.csv')\n",
        "\n",
        "y_value = df['class'] # set the y\n",
        "y_values = np.ravel(y_value) # change to an array (list)\n",
        "\n",
        "x_values = df.drop('class', axis=1) # drop the y from the dataframe\n",
        "\n",
        "# split data into training and test\n",
        "from sklearn.model_selection  import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(x_values, y_value, test_size = 0.2, random_state=4567, stratify=y_value)\n",
        "\n",
        "# print the shapes to check everything is OK\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_train.shape)\n",
        "print(Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "C5ihqxRoaOhD",
        "outputId": "712f1d85-5299-426c-f11d-e33571315dfd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'credit_data_final.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-52387832.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'credit_data_final.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# set the y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'credit_data_final.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling and Evaluation\n",
        "We will set up algorithms for logistic regression (the previous winner) and then our new algorithms.\n",
        "\n",
        "Just to look at the impact of hyperparameter optimisation, we will set them up initially with default hyperparameters and compare their performance (on the training data):"
      ],
      "metadata": {
        "id": "ZKfCtNgkbJx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression as LogR\n",
        "from sklearn.ensemble import RandomForestClassifier as RF\n",
        "from sklearn.ensemble import GradientBoostingClassifier as GBDT\n",
        "from xgboost import XGBClassifier as XGB\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "LogR_algo = LogR()\n",
        "LogR_model = LogR_algo.fit(X_train, Y_train)\n",
        "\n",
        "RF_algo = RF()\n",
        "RF_model = RF_algo.fit(X_train, Y_train)\n",
        "\n",
        "GBDT_algo = GBDT()\n",
        "GBDT_model = GBDT_algo.fit(X_train, Y_train)\n",
        "\n",
        "XGB_algo = XGB()\n",
        "XGB_model = XGB_algo.fit(X_train, Y_train)\n",
        "\n",
        "models = [LogR_model, RF_model, GBDT_model, XGB_model]\n",
        "names = ['Logistic Regression', 'Random Forest', 'GBDT', 'XGBDT']\n",
        "\n",
        "for i in range(4):\n",
        "  print(f\"Model: {names[i]}\")\n",
        "\n",
        "  # predict based on training data\n",
        "  predict = models[i].predict(X_train)\n",
        "\n",
        "  # Calculate precision, recall, and F1-score\n",
        "  precision, recall, f1_score, _ = precision_recall_fscore_support(Y_train, predict, average='macro')\n",
        "  print(f\"Macro Precision: {precision}\")\n",
        "  print(f\"Macro Recall: {recall}\")\n",
        "  print(f\"Macro F1-score: {f1_score}\")\n",
        "  print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "EXShsbWCctwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest and XGBDT score perfectly - but is it overfitting? Let's hyperparameter tune them and see the scores again (on training data):"
      ],
      "metadata": {
        "id": "OnwUdBfsdT1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "# we get a load of warnings running the code so will supress them\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# create a hyperparameter search function for re-usability\n",
        "def random_search(algo, hyperparameters, X_train, Y_train):\n",
        "  # do the search using 5 folds/chunks\n",
        "  clf = RandomizedSearchCV(algo, hyperparameters, cv=5, random_state=2015,\n",
        "                          scoring='precision_macro', n_iter=20, refit=True)\n",
        "\n",
        "  # pass the data to fit/train\n",
        "  clf.fit(X_train, Y_train)\n",
        "\n",
        "  return clf.best_params_\n",
        "\n",
        "# Logistic Regression\n",
        "LogR_tuned_parameters = {\n",
        "    'solver': ['liblinear'], # only this one as it does both L1 and L2\n",
        "    # C is the equivalent of alpha in L1/L2 regression - how much regularisation\n",
        "    'C': uniform(loc=0.1, scale=19.9),  # Draw from a uniform distribution between 0.1 and 20\n",
        "    'penalty': ['l1', 'l2', 'elasticnet', None] # elasticnet is a mix of L1 and L2\n",
        "}\n",
        "\n",
        "LogR_best_params = random_search(LogR_algo, LogR_tuned_parameters, X_train, Y_train)\n",
        "\n",
        "\n",
        "# Random Forest\n",
        "RF_tuned_parameters = {\n",
        "    'n_estimators': randint(50, 500), # Draw from a uniform distribution between 50 and 500\n",
        "    'max_depth': randint(2, 7),  # Draw from a uniform distribution between 2 and 7\n",
        "    'min_samples_split': randint(2, 7),  # Draw from a uniform distribution between 2 and 7\n",
        "    'max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "RF_best_params = random_search(RF_algo, RF_tuned_parameters, X_train, Y_train)\n",
        "\n",
        "\n",
        "# GBDT\n",
        "GBDT_tuned_parameters = {\n",
        "    'n_estimators': randint(25, 250), # Draw from a uniform distribution between 50 and 500\n",
        "    'learning_rate': uniform(loc=0.01, scale=4.99),  # Draw from a uniform distribution between 0.01 and 5\n",
        "    'criterion': ['friedman_mse', 'squared_error'],\n",
        "    'max_depth': randint(2, 7)  # Draw from a uniform distribution between 2 and 7\n",
        "}\n",
        "\n",
        "GBDT_best_params = random_search(GBDT_algo, GBDT_tuned_parameters, X_train, Y_train)\n",
        "\n",
        "\n",
        "# XGBDT\n",
        "XGB_tuned_parameters = {\n",
        "    'n_estimators': randint(25, 250), # Draw from a uniform distribution between 50 and 500\n",
        "    # eta is learning rate\n",
        "    'eta': uniform(loc=0.01, scale=4.99),  # Draw from a uniform distribution between 0.01 and 5\n",
        "    # objective is the same as criterion\n",
        "    'objective': ['binary:logistic', 'binary:hinge'],\n",
        "    'max_depth': randint(2, 7)  # Draw from a uniform distribution between 2 and 7\n",
        "}\n",
        "\n",
        "XGB_best_params = random_search(XGB_algo, XGB_tuned_parameters, X_train, Y_train)\n",
        "\n",
        "\n",
        "# Train the models\n",
        "LogR_algo = LogR(**LogR_best_params)\n",
        "LogR_model = LogR_algo.fit(X_train, Y_train)\n",
        "\n",
        "RF_algo = RF(**RF_best_params)\n",
        "RF_model = RF_algo.fit(X_train, Y_train)\n",
        "\n",
        "GBDT_algo = GBDT(**GBDT_best_params)\n",
        "GBDT_model = GBDT_algo.fit(X_train, Y_train)\n",
        "\n",
        "XGB_algo = XGB(**XGB_best_params)\n",
        "XGB_model = XGB_algo.fit(X_train, Y_train)\n",
        "\n",
        "\n",
        "# score the models\n",
        "models = [LogR_model, RF_model, GBDT_model, XGB_model] # redo this or it uses the old models\n",
        "\n",
        "for i in range(len(models)): # for every model in the models list\n",
        "  print(f\"Model: {names[i]}\")\n",
        "\n",
        "  # predict based on training data\n",
        "  predict = models[i].predict(X_train)\n",
        "\n",
        "  # Calculate precision, recall, and F1-score\n",
        "  precision, recall, f1_score, _ = precision_recall_fscore_support(Y_train, predict, average='macro')\n",
        "  print(f\"Macro Precision: {precision}\")\n",
        "  print(f\"Macro Recall: {recall}\")\n",
        "  print(f\"Macro F1-score: {f1_score}\")\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "id": "VoeCpo9Wdns6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our scores are ... a bit different from last time. In fact GBDT went up to perfect. However, the real test is the score on our test data:"
      ],
      "metadata": {
        "id": "7yEN6ODyjnD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(4):\n",
        "  print(f\"Model: {names[i]}\")\n",
        "\n",
        "  # predict based on TEST data\n",
        "  predict = models[i].predict(X_test)\n",
        "\n",
        "  # Calculate precision, recall, and F1-score\n",
        "  precision, recall, f1_score, _ = precision_recall_fscore_support(Y_test, predict, average='macro')\n",
        "  print(f\"Macro Precision: {precision}\")\n",
        "  print(f\"Macro Recall: {recall}\")\n",
        "  print(f\"Macro F1-score: {f1_score}\")\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "id": "Vp6cSADFkEfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar to last time, our best scorer for our prefered metric (_macro precision_) scores worse for everything else. We can make a good case to look further at both Random Forest and GBDT. So let's do that:"
      ],
      "metadata": {
        "id": "M3m661i8kROe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay as CM\n",
        "\n",
        "# Random Forest\n",
        "print(\"Random Forest Confusion Matrix\")\n",
        "predict = RF_model.predict(X_test)\n",
        "CM.from_predictions(Y_test, predict)"
      ],
      "metadata": {
        "id": "h-T7gM1Okocz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GBDT\n",
        "print(\"GBDT Confusion Matrix\")\n",
        "predict = GBDT_model.predict(X_test)\n",
        "print(CM.from_predictions(Y_test, predict))"
      ],
      "metadata": {
        "id": "9a0qWs8tldCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see they are wrong in different ways. Because we care most about minimising cases we predict \"0\" (good to loan to) and in fact they are a \"1\" (bad to loan to), GBDT should be best. Random Forest misclassifies 56 cases in this way (more than Logistic Regression), while GBDT only 31. Also, random forest only predicts \"1\" a total of 4 times. GBDT is much more balanced in the predictions it makes for each class.\n",
        "\n",
        "So GBDT is the winner.\n"
      ],
      "metadata": {
        "id": "D1XukG16liI0"
      }
    }
  ]
}